{
  "dataset_reader": {
    "class_name": "paraphraser_reader",
    "data_path": "{DOWNLOADS_PATH}/paraphraser_data"
  },
  "dataset_iterator": {
    "class_name": "siamese_iterator",
    "seed": 243
  },
  "chainer": {
    "in": ["x"],
    "in_y": ["y"],
    "pipe": [
      {
        "id": "preproc",
        "class_name": "siamese_preprocessor",
        "use_matrix": false,
        "max_sequence_length": 28,
        "fit_on": ["x"],
        "in": ["x"],
        "out": ["x_proc"],
        "sent_vocab": {
          "id": "siam_sent_vocab",
          "class_name": "simple_vocab",
          "save_path": "{MODELS_PATH}/paraphraser_elmo_ft_pre_1_vocabs/sent.dict",
          "load_path": "{MODELS_PATH}/paraphraser_elmo_ft_pre_1_vocabs/sent.dict"
        },
        "tokenizer": {
          "class_name": "nltk_tokenizer"
        },
        "vocab": {
          "id": "siam_vocab",
          "class_name": "simple_vocab",
          "save_path": "{MODELS_PATH}/paraphraser_elmo_ft_pre_1_vocabs/tok.dict",
          "load_path": "{MODELS_PATH}/paraphraser_elmo_ft_pre_1_vocabs/tok.dict"
        },
        "embedder": {
          "id": "siam_embedder",
          "class_name": "elmo_embedder",
          "elmo_output_names": [
            "elmo"
          ],
          "mini_batch_size": 8,
          "spec": "{DOWNLOADS_PATH}/embeddings/elmo_news_wmt11-16-simple_reduce_para_pre_fine_tuned_ep1"
        }
      },
      {
        "id": "embeddings",
        "class_name": "emb_mat_assembler",
        "embedder": "#siam_embedder",
        "vocab": "#siam_vocab"
      },
      {
        "id": "model",
        "class_name": "mpm_nn",
        "len_vocab": "#siam_vocab.len",
        "use_matrix": "#preproc.use_matrix",
        "attention": true,
        "max_sequence_length": "#preproc.max_sequence_length",
        "emb_matrix": "#embeddings.emb_mat",
        "embedding_dim": "#siam_embedder.dim",
        "seed": 243,
        "hidden_dim": 200,
        "learning_rate": 0.001,
        "triplet_loss": false,
        "batch_size": 256,
        "save_path": "{MODELS_PATH}/paraphraser_elmo_ft_pre_1_model/model_weights.h5",
        "load_path": "{MODELS_PATH}/paraphraser_elmo_ft_pre_1_model/model_weights.h5"
      },
      {
        "in": ["x_proc"],
        "in_y": ["y"],
        "out": ["y_predicted"],
        "class_name": "siamese_predictor",
        "model": "#model",
        "ranking": false,
        "attention": true,
        "batch_size": "#model.batch_size",
        "preproc_func": "#preproc.__call__"
      }
    ],
    "out": ["y_predicted"]
  },
  "train": {
    "epochs": 1,
    "batch_size": 256,
    "pytest_max_batches": 2,
    "train_metrics": ["f1", "acc", "log_loss"],
    "metrics": ["f1", "acc", "log_loss"],
    "validation_patience": 1,
    "val_every_n_epochs": 1,
    "log_every_n_batches": 24,
    "class_name": "nn_trainer",
    "evaluation_targets": [
      "valid",
      "test"
    ]
  },
  "metadata": {
    "variables": {
      "ROOT_PATH": "~/.deeppavlov",
      "DOWNLOADS_PATH": "{ROOT_PATH}/downloads",
      "MODELS_PATH": "{ROOT_PATH}/models"
    },
    "requirements": [
      "{DEEPPAVLOV_PATH}/requirements/tf.txt",
      "{DEEPPAVLOV_PATH}/requirements/tf-hub.txt"
    ],
    "download": [
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/paraphraser_elmo_ft_pre_1_model.tar.gz",
        "subdir": "{MODELS_PATH}"
      },
      {
        "url": "http://files.deeppavlov.ai/datasets/paraphraser.zip",
        "subdir": "{DOWNLOADS_PATH}/paraphraser_data"
      },
      {
        "url": "http://files.deeppavlov.ai/datasets/paraphraser_gold.zip",
        "subdir": "{DOWNLOADS_PATH}/paraphraser_data"
      },
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/elmo_news_wmt11-16-simple_reduce_para_pretrain_fine_tuned_ep1.tar.gz",
        "subdir": "{DOWNLOADS_PATH}/embeddings/elmo_news_wmt11-16-simple_reduce_para_pre_fine_tuned_ep1"
      }
    ]
  }
}